# -*- coding: utf-8 -*-
"""SkulBSscrapper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BKdgoozKSlAM_VhAfrJueX7ti7KjTuHi
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup
from google.colab import drive
drive.mount('/drive')

def follow_through(site):
  webpage = site
  
  response = requests.get(webpage)
  
  bs = BeautifulSoup(response.content,'html5lib')
  bs = bs.find('div',attrs={'class':'page has-right-rail'}).find('div',attrs={'id':'content'}).find('div',attrs={'class':'mw-parser-output'})
  rarity =bs.find('aside').find('div',attrs={'data-source':'rarity'}).find('a').get_text()
  effect_section = bs.find_all('ul')[1]
  
  effect = ''
  for i,row in enumerate(effect_section.find_all('li')):
    effect = effect + row.get_text() + ' '
    
  return [effect, rarity]

web = 'https://skul.fandom.com'
site = web + '/wiki/Equipment'
response = requests.get(site)
bs = BeautifulSoup(response.content,'html5lib')
div = bs.find('div',attrs={'class':'mw-parser-output'})
div = div.find_all('table',attrs={'class':'sortable fandom-table'})

items = [['Name', 'Image', 'Inscription_1', 'Inscription_2','rarity','effect']]

for i in div:
  row = i.find_all('tr')
  
  #For each row
  for j in row:
  
    
    a = j.find_all('a')
    if (a!=[]):
      for k,row in enumerate(a):
        if (k == 0):
          image = row['href']
          
        if (k==1):
          
          item = row.get_text()
          link = row['href']
          
          details = follow_through(web+link)
          effect = details[0]
          rarity = details[1]

        if (k==2):
          inscription_1 = row.get_text()
        if (k==3):
          inscription_2 = row.get_text()
      
      
    
      items.append([item,image,inscription_1,inscription_2,rarity,effect])
    
    
    
    #print('***********')
df = pd.DataFrame(items)
df.to_csv('/drive/My Drive/Scrappers/results.csv', index=False)